{
  "data": {
    "dataset": "wos",
    "data_dir": "data",
    "train_file": "wos_train_raw_tokenized.json",
    "val_file": "wos_val_raw_tokenized.json",
    "test_file": "wos_test_raw_tokenized.json",
    "prob_json": "wos_prob_raw.json",
    "hierarchy": "wos.taxonomy",
    "tokenized": true,
    "name": "hitin"
  },
  "vocabulary": {
    "dir": "vocab",
    "vocab_dict": "word.dict",
    "max_token_vocab": 60000,
    "label_dict": "label.dict"
  },
  "embedding": {
    "token": {
      "dimension": 300,
      "type": "pretrain",
      "pretrained_file": "glove.6B.300d.txt",
      "dropout": 0.5,
      "init_type": "kaiming_uniform"
    },
    "label": {
      "dimension": 300,
      "type": "random",
      "dropout": 0.5,
      "init_type": "kaiming_uniform"
    }
  },
  "text_encoder": {
    "type": "bert",
    "bert_model_dir": "bert-base-uncased",
    "max_length": 512,
    "freeze_bert": false,
    "RNN": {
      "bidirectional": true,
      "num_layers": 1,
      "type": "GRU",
      "hidden_dimension": 100,
      "dropout": 0.1
    },
    "CNN": {
      "kernel_size": [2, 3, 4],
      "num_kernel": 100
    },
    "topK_max_pooling": 1
  },
  "structure_encoder": {
    "type": "TIN",
    "node": {
      "type": "text",
      "dimension": 768,
      "dropout": 0.05
    }
  },
  "model": {
    "type": "HiAGM-TP",
    "linear_transformation": {
      "text_dimension": 768,
      "node_dimension": 768,
      "dropout": 0.1
    },
    "classifier": {
      "num_layer": 1,
      "dropout": 0.5
        }
  },
  "train": {
    "optimizer": {
      "type": "Adam",
      "learning_rate": 2e-5,
      "lr_decay": 1.0,
      "lr_patience": 5,
      "early_stopping": 50,
      "set_to_zero_decay_classif" : true
    },
    "batch_size": 16,
    "start_epoch": 0,
    "end_epoch": 20,
    "losstype": "standard",
    "loss": {
      "classification": "BCEWithLogitsLoss",
      "recursive_regularization": {
        "flag": true,
        "penalty": 0.000001
      }
    },
    "device_setting": {
      "device": "cuda",
      "visible_device_list": "0",
      "num_workers": 0
    },
    "checkpoint": {
      "dir": "wos_tin_bert",
      "max_number": 10,
      "save_best": ["Macro_F1", "Micro_F1"]
    }
  },
  "eval": {
    "batch_size": 16,
    "threshold": 0.5, 
    "type" : "set"
  },
   "test": {
    "best_checkpoint": "best_micro_tin_bert",
    "batch_size": 16
  },
  "log": {
    "level": "info",
    "filename": "tin-wos-bert.log"
  }
}
